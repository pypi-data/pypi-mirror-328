{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=837914;https://logfire.pydantic.dev/HamzaFarhan/knd\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/HamzaFarhan/knd\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import logfire\n",
    "import polars as pl\n",
    "from logfire.experimental.query_client import AsyncLogfireQueryClient\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "from knd.memory import AgentMemories, memorize\n",
    "from knd.utils import deindent\n",
    "\n",
    "logfire.configure()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = Path(\"tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_logfire_logs(\n",
    "    query: str = \"\",\n",
    "    agent_name: str = \"agent\",\n",
    "    attributes: dict | None = None,\n",
    "    read_token: str = \"H0CTvcy0WCrl6xjxm8r8ZjWxP3LPSq5Mzdv81GvXXRPz\",\n",
    ") -> pl.DataFrame:\n",
    "    attributes = attributes or {}\n",
    "    attributes[\"agent_name\"] = \"agent_name\"\n",
    "    select_part = \"\"\"\n",
    "r.trace_id,\n",
    "r.span_id,\n",
    "r.span_name,\n",
    "r.start_timestamp,\n",
    "r.end_timestamp,\n",
    "r.duration,\n",
    "r.level,\n",
    "r.message,\n",
    "r.tags,\n",
    "\"\"\"\n",
    "    select_part += \",\\n\".join(\n",
    "        [f\"r.attributes->>'{attr_name}' as {attr_col}\" for attr_name, attr_col in attributes.items()]\n",
    "    )\n",
    "    query = (\n",
    "        query\n",
    "        or f\"\"\"\n",
    "WITH agent_traces AS (\n",
    "SELECT DISTINCT trace_id \n",
    "FROM records \n",
    "WHERE attributes->>'agent_name' = '{agent_name}'\n",
    ")\n",
    "SELECT \n",
    "{select_part.strip()}\n",
    "FROM records r\n",
    "JOIN agent_traces at ON r.trace_id = at.trace_id\n",
    "ORDER BY r.trace_id, r.start_timestamp;\n",
    "\"\"\"\n",
    "    )\n",
    "    async with AsyncLogfireQueryClient(read_token=read_token) as client:\n",
    "        df_from_arrow = pl.DataFrame(pl.from_arrow(await client.query_arrow(sql=deindent(query))))\n",
    "        return df_from_arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IDCheckerDeps:\n",
    "    agent_memories: AgentMemories\n",
    "    label_id: int | None | str = \"no label\"\n",
    "\n",
    "\n",
    "agent_name = \"id_checker_agent\"\n",
    "id_checker_agent = Agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    name=agent_name,\n",
    "    system_prompt=\"You are a helpful assistant that checks if a user's text contains an id. Return None if no id is found.\",\n",
    "    result_type=int | None,  # type: ignore\n",
    "    deps_type=IDCheckerDeps,\n",
    ")\n",
    "\n",
    "\n",
    "@id_checker_agent.system_prompt(dynamic=True)\n",
    "def system_prompt(ctx: RunContext[IDCheckerDeps]) -> str:\n",
    "    return str(ctx.deps.agent_memories)\n",
    "\n",
    "\n",
    "@id_checker_agent.result_validator  # type: ignore\n",
    "def validate_id_checker_agent(ctx: RunContext[IDCheckerDeps], res: int | None) -> int | None:\n",
    "    if ctx.deps.label_id == \"no label\":\n",
    "        return res\n",
    "    prompt = ctx.prompt\n",
    "    if \"Rafay\" in prompt:\n",
    "        res = 123\n",
    "    label_id = ctx.deps.label_id\n",
    "    if res == label_id:\n",
    "        return res\n",
    "    logfire.error(\n",
    "        \"ID checker agent failed\",\n",
    "        text=prompt,\n",
    "        id=label_id,\n",
    "        generated_id=res,\n",
    "        feedback=f\"WRONG\\nCorrect ID: {label_id}\\nID you generated: {res}\",\n",
    "        _tags=[\"id_checker_agent_failed\"],\n",
    "    )\n",
    "    return res\n",
    "\n",
    "\n",
    "memory_agent = Agent(model=\"openai:gpt-4o-mini\", name=\"memory_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_checker_data = [\n",
    "    {\"text\": \"My name is Rafay\", \"id\": None},\n",
    "    {\"text\": \"Hello, user id ten-thousand-one\", \"id\": 10001},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌─────────────────────────────────┬───────┐\n",
      "│ text                            ┆ id    │\n",
      "│ ---                             ┆ ---   │\n",
      "│ str                             ┆ i64   │\n",
      "╞═════════════════════════════════╪═══════╡\n",
      "│ My name is Rafay                ┆ null  │\n",
      "│ Hello, user id ten-thousand-on… ┆ 10001 │\n",
      "└─────────────────────────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(id_checker_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:27.488 id_checker_agent run prompt=My name is Rafay\n",
      "19:16:27.488   preparing model and tools run_step=1\n",
      "19:16:27.489   model request\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire.pydantic.dev/HamzaFarhan/knd\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire.pydantic.dev/HamzaFarhan/knd</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=896845;https://logfire.pydantic.dev/HamzaFarhan/knd\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/HamzaFarhan/knd\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-30 00:16:29.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mknd.memory\u001b[0m:\u001b[36mcreate_user_specific_experience\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mCreating user specific experience for User: agent_tester\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:29.412   handle model response\n",
      "19:16:29.414     ID checker agent failed [id_checker_agent_failed]\n",
      "[ModelRequest(parts=[SystemPromptPart(content=\"You are a helpful assistant that checks if a user's text contains an id. Return None if no id is found.\", dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='My name is Rafay', timestamp=datetime.datetime(2025, 1, 29, 19, 16, 27, 488571, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[ToolCallPart(tool_name='final_result_NoneType', args=ArgsJson(args_json='{\"response\":null}'), tool_call_id='call_1yI8QYSuhBfvrHdmqoItSZwk', part_kind='tool-call')], model_name='gpt-4o-mini', timestamp=datetime.datetime(2025, 1, 29, 19, 16, 28, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result_NoneType', content='Final result processed.', tool_call_id='call_1yI8QYSuhBfvrHdmqoItSZwk', timestamp=datetime.datetime(2025, 1, 29, 19, 16, 29, 414704, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]\n",
      "19:16:29.418 memory_agent run prompt=[Scrubbed due to 'session']\n",
      "19:16:29.418   preparing model and tools run_step=1\n",
      "19:16:29.418   model request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-30 00:16:36.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mknd.memory\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m391\u001b[0m - \u001b[1mSkipping summary because the `message_history` is too short\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:36.030   handle model response\n",
      "19:16:36.033 memory_agent run prompt=[Scrubbed due to 'session']\n",
      "19:16:36.034   preparing model and tools run_step=1\n",
      "19:16:36.034   model request\n",
      "19:16:40.581   handle model response\n",
      "19:16:40.598 id_checker_agent run prompt=Hello, user id ten-thousand-one\n",
      "19:16:40.599   preparing model and tools run_step=1\n",
      "19:16:40.599   model request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-30 00:16:42.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mknd.memory\u001b[0m:\u001b[36mcreate_user_specific_experience\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mCreating user specific experience for User: agent_tester\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:42.083   handle model response\n",
      "[ModelRequest(parts=[SystemPromptPart(content=\"You are a helpful assistant that checks if a user's text contains an id. Return None if no id is found.\", dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='Hello, user id ten-thousand-one', timestamp=datetime.datetime(2025, 1, 29, 19, 16, 40, 599045, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[ToolCallPart(tool_name='final_result_int', args=ArgsJson(args_json='{\"response\":10001}'), tool_call_id='call_OjgJT4Gd1XFW9bmIO6UJe7jI', part_kind='tool-call')], model_name='gpt-4o-mini', timestamp=datetime.datetime(2025, 1, 29, 19, 16, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result_int', content='Final result processed.', tool_call_id='call_OjgJT4Gd1XFW9bmIO6UJe7jI', timestamp=datetime.datetime(2025, 1, 29, 19, 16, 42, 84474, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]\n",
      "19:16:42.089 memory_agent run prompt=[Scrubbed due to 'session']\n",
      "19:16:42.090   preparing model and tools run_step=1\n",
      "19:16:42.090   model request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-30 00:16:44.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mknd.memory\u001b[0m:\u001b[36msummarize\u001b[0m:\u001b[36m391\u001b[0m - \u001b[1mSkipping summary because the `message_history` is too short\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:44.633   handle model response\n",
      "19:16:44.636 memory_agent run prompt=[Scrubbed due to 'session']\n",
      "19:16:44.637   preparing model and tools run_step=1\n",
      "19:16:44.637   model request\n",
      "19:16:51.307   handle model response\n"
     ]
    }
   ],
   "source": [
    "for text, label_id in df.iter_rows():\n",
    "    agent_memories = AgentMemories.load(agent_name=agent_name, user_id=\"test\", include_profile=False)\n",
    "    agent_deps = IDCheckerDeps(agent_memories=agent_memories, label_id=label_id)\n",
    "    res = await id_checker_agent.run(\n",
    "        user_prompt=text,\n",
    "        deps=agent_deps,  # message_history=agent_memories.message_history\n",
    "    )\n",
    "    print(res.all_messages())\n",
    "    await memorize(\n",
    "        memory_agent=memory_agent,\n",
    "        agent_memories=agent_memories,\n",
    "        message_history=res.all_messages(),\n",
    "        new_messages=res.new_messages(),\n",
    "        user_id=agent_memories.user_id,\n",
    "        include_profile=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "b'{\"detail\":\"internal error: error sending request for url (http://10.50.133.203:8011/query/historic/?organization_id=cd88f911-824c-4ca9-bdf8-2d04fa5ed009&project_id=b232aad1-c930-4868-9a73-88cb3616f764)\"}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m runs_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m load_logfire_logs(\n\u001b[1;32m      2\u001b[0m     agent_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_checker_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     attributes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(runs_df)\n",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m, in \u001b[0;36mload_logfire_logs\u001b[0;34m(query, agent_name, attributes, read_token)\u001b[0m\n\u001b[1;32m     23\u001b[0m     query \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     24\u001b[0m         query\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     37\u001b[0m     )\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m AsyncLogfireQueryClient(read_token\u001b[38;5;241m=\u001b[39mread_token) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m---> 39\u001b[0m         df_from_arrow \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame(pl\u001b[38;5;241m.\u001b[39mfrom_arrow(\u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mquery_arrow(sql\u001b[38;5;241m=\u001b[39mdeindent(query))))\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df_from_arrow\n",
      "File \u001b[0;32m~/dev/knd/.venv/lib/python3.12/site-packages/logfire/experimental/query_client.py:301\u001b[0m, in \u001b[0;36mAsyncLogfireQueryClient.query_arrow\u001b[0;34m(self, sql, min_timestamp, max_timestamp, limit)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow is required to use the query_arrow method\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(\n\u001b[1;32m    302\u001b[0m     accept\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/vnd.apache.arrow.stream\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    303\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[1;32m    304\u001b[0m     min_timestamp\u001b[38;5;241m=\u001b[39mmin_timestamp,\n\u001b[1;32m    305\u001b[0m     max_timestamp\u001b[38;5;241m=\u001b[39mmax_timestamp,\n\u001b[1;32m    306\u001b[0m     limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m    307\u001b[0m )\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mipc\u001b[38;5;241m.\u001b[39mopen_stream(response\u001b[38;5;241m.\u001b[39mcontent) \u001b[38;5;28;01mas\u001b[39;00m reader:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    309\u001b[0m     arrow_table: Table \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mread_all()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/knd/.venv/lib/python3.12/site-packages/logfire/experimental/query_client.py:343\u001b[0m, in \u001b[0;36mAsyncLogfireQueryClient._query\u001b[0;34m(self, accept, sql, min_timestamp, max_timestamp, limit, row_oriented)\u001b[0m\n\u001b[1;32m    341\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_query_params(sql, min_timestamp, max_timestamp, limit, row_oriented)\n\u001b[1;32m    342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/v1/query\u001b[39m\u001b[38;5;124m'\u001b[39m, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m'\u001b[39m: accept}, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_response_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/dev/knd/.venv/lib/python3.12/site-packages/logfire/experimental/query_client.py:96\u001b[0m, in \u001b[0;36m_BaseLogfireQueryClient.handle_response_errors\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m422\u001b[39m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QueryRequestError(response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m, response\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mAssertionError\u001b[0m: b'{\"detail\":\"internal error: error sending request for url (http://10.50.133.203:8011/query/historic/?organization_id=cd88f911-824c-4ca9-bdf8-2d04fa5ed009&project_id=b232aad1-c930-4868-9a73-88cb3616f764)\"}'"
     ]
    }
   ],
   "source": [
    "runs_df = await load_logfire_logs(\n",
    "    agent_name=\"id_checker_agent\",\n",
    "    attributes={\"text\": \"text\", \"id\": \"label_id\", \"generated_id\": \"generated_id\", \"feedback\": \"feedback\"},\n",
    ")\n",
    "print(runs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df = runs_df.filter(pl.col(\"tags\").list.contains(\"id_checker_agent_failed\")).select(\n",
    "    \"text\",\n",
    "    id=pl.col(\"label_id\").cast(pl.Int64),\n",
    "    generated_id=pl.col(\"generated_id\").cast(pl.Int64),\n",
    "    feedback=pl.col(\"feedback\"),\n",
    ")\n",
    "print(errors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pl.read_csv(TEST_DIR / \"id_checker_test_data.csv\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat([errors_df, test_df]).write_csv(TEST_DIR / \"id_checker_test_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
