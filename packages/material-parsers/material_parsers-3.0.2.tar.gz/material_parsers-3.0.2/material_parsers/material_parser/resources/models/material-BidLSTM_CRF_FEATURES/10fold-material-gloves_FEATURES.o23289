Using TensorFlow backend.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/lfoppian0/anaconda3/envs/tensorflow-gpu_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Loading data...
7506 train sequences
834 validation sequences
927 evaluation sequences
embedding_lmdb_path is not specified in the embeddings registry, so the embeddings will be loaded in memory...
loading embeddings...
path: /lustre/group/tdm/Luca/delft/delft/data/embeddings/glove.840B.300d.txt
embeddings loaded for 2196017 words and 300 dimensions

------------------------ fold 0--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 50)     10200       time_distributed_1[0][0]         
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_2[0][0]         
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, None, 358)    0           concatenate_1[0][0]              
__________________________________________________________________________________________________
bidirectional_3 (Bidirectional) (None, None, 200)    367200      dropout_2[0][0]                  
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, None, 200)    0           bidirectional_3[0][0]            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, None, 100)    20100       dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, None, 18)     1818        dense_1[0][0]                    
__________________________________________________________________________________________________
chain_crf_1 (ChainCRF)          (None, None, 18)     360         dense_2[0][0]                    
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 86s 227ms/step - loss: 46.6993
	f1 (micro): 86.34
Epoch 2/100

376/376 [==============================] - 70s 187ms/step - loss: 44.8291
	f1 (micro): 92.36
Epoch 3/100

376/376 [==============================] - 70s 186ms/step - loss: 44.2987
	f1 (micro): 93.89
Epoch 4/100

376/376 [==============================] - 70s 185ms/step - loss: 43.7505
	f1 (micro): 94.95
Epoch 5/100

376/376 [==============================] - 69s 182ms/step - loss: 43.9586
	f1 (micro): 94.97
Epoch 6/100

376/376 [==============================] - 69s 183ms/step - loss: 44.1095
	f1 (micro): 95.62
Epoch 7/100

376/376 [==============================] - 66s 176ms/step - loss: 44.0066
	f1 (micro): 95.84
Epoch 8/100

376/376 [==============================] - 66s 177ms/step - loss: 43.7752
	f1 (micro): 96.00
Epoch 9/100

376/376 [==============================] - 68s 181ms/step - loss: 42.9302
	f1 (micro): 96.38
Epoch 10/100

376/376 [==============================] - 71s 188ms/step - loss: 43.9317
	f1 (micro): 96.25
Epoch 11/100

376/376 [==============================] - 68s 181ms/step - loss: 43.6278
	f1 (micro): 95.71
Epoch 12/100

376/376 [==============================] - 68s 181ms/step - loss: 43.7255
	f1 (micro): 96.20
Epoch 13/100

376/376 [==============================] - 69s 183ms/step - loss: 43.9799
	f1 (micro): 96.00
Epoch 14/100

376/376 [==============================] - 69s 182ms/step - loss: 43.3908
	f1 (micro): 96.58
Epoch 15/100

376/376 [==============================] - 68s 181ms/step - loss: 42.8531
	f1 (micro): 95.79
Epoch 16/100

376/376 [==============================] - 70s 186ms/step - loss: 43.7539
	f1 (micro): 96.00
Epoch 17/100

376/376 [==============================] - 68s 181ms/step - loss: 43.4270
	f1 (micro): 96.59
Epoch 18/100

376/376 [==============================] - 68s 182ms/step - loss: 43.5159
	f1 (micro): 96.37
Epoch 19/100

376/376 [==============================] - 68s 181ms/step - loss: 44.0214
	f1 (micro): 96.59
Epoch 20/100

376/376 [==============================] - 68s 180ms/step - loss: 43.4007
	f1 (micro): 96.63
Epoch 21/100

376/376 [==============================] - 68s 181ms/step - loss: 43.2758
	f1 (micro): 96.92
Epoch 22/100

376/376 [==============================] - 69s 183ms/step - loss: 42.9686
	f1 (micro): 96.75
Epoch 23/100

376/376 [==============================] - 69s 183ms/step - loss: 43.3414
	f1 (micro): 96.71
Epoch 24/100

376/376 [==============================] - 68s 181ms/step - loss: 43.8104
	f1 (micro): 96.59
Epoch 25/100

376/376 [==============================] - 68s 182ms/step - loss: 43.6222
	f1 (micro): 96.71
Epoch 26/100

376/376 [==============================] - 69s 183ms/step - loss: 43.6665
	f1 (micro): 96.67

------------------------ fold 1--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 50)     10200       time_distributed_3[0][0]         
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_4[0][0]         
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, None, 358)    0           concatenate_2[0][0]              
__________________________________________________________________________________________________
bidirectional_6 (Bidirectional) (None, None, 200)    367200      dropout_5[0][0]                  
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, None, 200)    0           bidirectional_6[0][0]            
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, None, 100)    20100       dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, None, 18)     1818        dense_3[0][0]                    
__________________________________________________________________________________________________
chain_crf_2 (ChainCRF)          (None, None, 18)     360         dense_4[0][0]                    
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 79s 211ms/step - loss: 46.4211
	f1 (micro): 85.80
Epoch 2/100

376/376 [==============================] - 70s 185ms/step - loss: 45.2561
	f1 (micro): 92.24
Epoch 3/100

376/376 [==============================] - 69s 184ms/step - loss: 44.8346
	f1 (micro): 93.14
Epoch 4/100

376/376 [==============================] - 69s 183ms/step - loss: 44.4062
	f1 (micro): 94.69
Epoch 5/100

376/376 [==============================] - 69s 183ms/step - loss: 44.0060
	f1 (micro): 95.78
Epoch 6/100

376/376 [==============================] - 69s 183ms/step - loss: 43.7383
	f1 (micro): 95.46
Epoch 7/100

376/376 [==============================] - 69s 184ms/step - loss: 44.0075
	f1 (micro): 95.39
Epoch 8/100

376/376 [==============================] - 69s 183ms/step - loss: 43.7542
	f1 (micro): 95.50
Epoch 9/100

376/376 [==============================] - 68s 182ms/step - loss: 43.0913
	f1 (micro): 95.84
Epoch 10/100

376/376 [==============================] - 68s 182ms/step - loss: 43.4432
	f1 (micro): 95.92
Epoch 11/100

376/376 [==============================] - 69s 184ms/step - loss: 44.1138
	f1 (micro): 95.67
Epoch 12/100

376/376 [==============================] - 70s 185ms/step - loss: 44.3975
	f1 (micro): 96.09
Epoch 13/100

376/376 [==============================] - 70s 187ms/step - loss: 43.2155
	f1 (micro): 95.93
Epoch 14/100

376/376 [==============================] - 70s 187ms/step - loss: 43.8775
	f1 (micro): 95.75
Epoch 15/100

376/376 [==============================] - 70s 187ms/step - loss: 43.8312
	f1 (micro): 96.04
Epoch 16/100

376/376 [==============================] - 69s 183ms/step - loss: 43.7338
	f1 (micro): 96.05
Epoch 17/100

376/376 [==============================] - 70s 185ms/step - loss: 45.2077
	f1 (micro): 96.26
Epoch 18/100

376/376 [==============================] - 69s 183ms/step - loss: 43.1050
	f1 (micro): 96.55
Epoch 19/100

376/376 [==============================] - 69s 184ms/step - loss: 43.8503
	f1 (micro): 96.80
Epoch 20/100

376/376 [==============================] - 70s 186ms/step - loss: 44.2569
	f1 (micro): 96.83
Epoch 21/100

376/376 [==============================] - 69s 184ms/step - loss: 43.1817
	f1 (micro): 96.84
Epoch 22/100

376/376 [==============================] - 69s 184ms/step - loss: 43.3593
	f1 (micro): 96.71
Epoch 23/100

376/376 [==============================] - 69s 183ms/step - loss: 43.0915
	f1 (micro): 96.22
Epoch 24/100

376/376 [==============================] - 69s 184ms/step - loss: 43.6697
	f1 (micro): 96.25
Epoch 25/100

376/376 [==============================] - 69s 184ms/step - loss: 43.1792
	f1 (micro): 96.59
Epoch 26/100

376/376 [==============================] - 71s 188ms/step - loss: 43.7099
	f1 (micro): 96.46

------------------------ fold 2--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 50)     10200       time_distributed_5[0][0]         
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_6[0][0]         
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, None, 358)    0           concatenate_3[0][0]              
__________________________________________________________________________________________________
bidirectional_9 (Bidirectional) (None, None, 200)    367200      dropout_8[0][0]                  
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, None, 200)    0           bidirectional_9[0][0]            
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, None, 100)    20100       dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, None, 18)     1818        dense_5[0][0]                    
__________________________________________________________________________________________________
chain_crf_3 (ChainCRF)          (None, None, 18)     360         dense_6[0][0]                    
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 85s 225ms/step - loss: 46.3850
	f1 (micro): 85.53
Epoch 2/100

376/376 [==============================] - 69s 183ms/step - loss: 44.6726
	f1 (micro): 93.57
Epoch 3/100

376/376 [==============================] - 68s 182ms/step - loss: 44.5524
	f1 (micro): 94.34
Epoch 4/100

376/376 [==============================] - 69s 184ms/step - loss: 44.9943
	f1 (micro): 95.49
Epoch 5/100

376/376 [==============================] - 68s 182ms/step - loss: 43.8754
	f1 (micro): 95.37
Epoch 6/100

376/376 [==============================] - 69s 183ms/step - loss: 44.4734
	f1 (micro): 95.74
Epoch 7/100

376/376 [==============================] - 70s 185ms/step - loss: 44.0754
	f1 (micro): 95.75
Epoch 8/100

376/376 [==============================] - 69s 183ms/step - loss: 44.5986
	f1 (micro): 96.08
Epoch 9/100

376/376 [==============================] - 68s 181ms/step - loss: 43.2681
	f1 (micro): 95.67
Epoch 10/100

376/376 [==============================] - 71s 189ms/step - loss: 44.2166
	f1 (micro): 95.91
Epoch 11/100

376/376 [==============================] - 70s 187ms/step - loss: 43.7533
	f1 (micro): 96.07
Epoch 12/100

376/376 [==============================] - 69s 185ms/step - loss: 43.4408
	f1 (micro): 96.03
Epoch 13/100

376/376 [==============================] - 70s 187ms/step - loss: 43.0795
	f1 (micro): 95.87

------------------------ fold 3--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 50)     10200       time_distributed_7[0][0]         
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_8[0][0]         
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, None, 358)    0           concatenate_4[0][0]              
__________________________________________________________________________________________________
bidirectional_12 (Bidirectional (None, None, 200)    367200      dropout_11[0][0]                 
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, None, 200)    0           bidirectional_12[0][0]           
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, None, 100)    20100       dropout_12[0][0]                 
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, None, 18)     1818        dense_7[0][0]                    
__________________________________________________________________________________________________
chain_crf_4 (ChainCRF)          (None, None, 18)     360         dense_8[0][0]                    
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100


376/376 [==============================] - 85s 226ms/step - loss: 46.9509
	f1 (micro): 86.81
Epoch 2/100

376/376 [==============================] - 71s 188ms/step - loss: 44.9301
	f1 (micro): 92.29
Epoch 3/100

376/376 [==============================] - 70s 185ms/step - loss: 44.4705
	f1 (micro): 93.98
Epoch 4/100

376/376 [==============================] - 68s 182ms/step - loss: 43.8034
	f1 (micro): 94.57
Epoch 5/100

376/376 [==============================] - 69s 182ms/step - loss: 44.3892
	f1 (micro): 95.30
Epoch 6/100

376/376 [==============================] - 68s 181ms/step - loss: 43.5042
	f1 (micro): 95.40
Epoch 7/100

376/376 [==============================] - 69s 182ms/step - loss: 44.0438
	f1 (micro): 95.16
Epoch 8/100

376/376 [==============================] - 68s 182ms/step - loss: 43.6624
	f1 (micro): 95.75
Epoch 9/100

376/376 [==============================] - 70s 185ms/step - loss: 44.3615
	f1 (micro): 95.82
Epoch 10/100

376/376 [==============================] - 69s 184ms/step - loss: 43.8007
	f1 (micro): 95.50
Epoch 11/100

376/376 [==============================] - 69s 183ms/step - loss: 44.3170
	f1 (micro): 95.82
Epoch 12/100

376/376 [==============================] - 68s 181ms/step - loss: 42.9589
	f1 (micro): 95.70
Epoch 13/100

376/376 [==============================] - 68s 181ms/step - loss: 43.1643
	f1 (micro): 96.12
Epoch 14/100

376/376 [==============================] - 68s 182ms/step - loss: 43.9684
	f1 (micro): 96.00
Epoch 15/100

376/376 [==============================] - 68s 181ms/step - loss: 43.1086
	f1 (micro): 96.13
Epoch 16/100

376/376 [==============================] - 69s 183ms/step - loss: 44.6412
	f1 (micro): 95.92
Epoch 17/100

376/376 [==============================] - 68s 182ms/step - loss: 42.9274
	f1 (micro): 96.25
Epoch 18/100

376/376 [==============================] - 68s 181ms/step - loss: 43.1828
	f1 (micro): 96.50
Epoch 19/100

376/376 [==============================] - 69s 184ms/step - loss: 43.7948
	f1 (micro): 96.38
Epoch 20/100

376/376 [==============================] - 68s 182ms/step - loss: 43.6946
	f1 (micro): 96.04
Epoch 21/100

376/376 [==============================] - 69s 184ms/step - loss: 43.1114
	f1 (micro): 96.09
Epoch 22/100

376/376 [==============================] - 69s 183ms/step - loss: 43.2574
	f1 (micro): 96.37
Epoch 23/100

376/376 [==============================] - 71s 190ms/step - loss: 43.8853
	f1 (micro): 96.17

------------------------ fold 4--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 50)     10200       time_distributed_9[0][0]         
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_10[0][0]        
                                                                 dropout_13[0][0]                 
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, None, 358)    0           concatenate_5[0][0]              
__________________________________________________________________________________________________
bidirectional_15 (Bidirectional (None, None, 200)    367200      dropout_14[0][0]                 
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, None, 200)    0           bidirectional_15[0][0]           
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, None, 100)    20100       dropout_15[0][0]                 
__________________________________________________________________________________________________
dense_10 (Dense)                (None, None, 18)     1818        dense_9[0][0]                    
__________________________________________________________________________________________________
chain_crf_5 (ChainCRF)          (None, None, 18)     360         dense_10[0][0]                   
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 84s 223ms/step - loss: 46.5624
	f1 (micro): 85.96
Epoch 2/100

376/376 [==============================] - 70s 186ms/step - loss: 44.8686
	f1 (micro): 92.66
Epoch 3/100

376/376 [==============================] - 68s 182ms/step - loss: 44.1879
	f1 (micro): 94.37
Epoch 4/100

376/376 [==============================] - 68s 182ms/step - loss: 43.8816
	f1 (micro): 94.95
Epoch 5/100

376/376 [==============================] - 68s 182ms/step - loss: 43.9752
	f1 (micro): 95.58
Epoch 6/100

376/376 [==============================] - 68s 182ms/step - loss: 44.2659
	f1 (micro): 95.82
Epoch 7/100

376/376 [==============================] - 69s 183ms/step - loss: 43.8541
	f1 (micro): 95.45
Epoch 8/100

376/376 [==============================] - 70s 186ms/step - loss: 44.0352
	f1 (micro): 95.83
Epoch 9/100

376/376 [==============================] - 71s 190ms/step - loss: 43.6192
	f1 (micro): 96.09
Epoch 10/100

376/376 [==============================] - 71s 188ms/step - loss: 44.7728
	f1 (micro): 96.34
Epoch 11/100

376/376 [==============================] - 70s 187ms/step - loss: 43.6518
	f1 (micro): 96.00
Epoch 12/100

376/376 [==============================] - 70s 187ms/step - loss: 44.0959
	f1 (micro): 96.00
Epoch 13/100

376/376 [==============================] - 70s 186ms/step - loss: 43.1148
	f1 (micro): 96.38
Epoch 14/100

376/376 [==============================] - 70s 186ms/step - loss: 43.5781
	f1 (micro): 96.29
Epoch 15/100

376/376 [==============================] - 69s 183ms/step - loss: 43.5548
	f1 (micro): 96.34
Epoch 16/100

376/376 [==============================] - 71s 188ms/step - loss: 43.7277
	f1 (micro): 96.09
Epoch 17/100

376/376 [==============================] - 70s 185ms/step - loss: 44.3052
	f1 (micro): 96.21
Epoch 18/100

376/376 [==============================] - 70s 185ms/step - loss: 43.2468
	f1 (micro): 96.04

------------------------ fold 5--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_12 (TimeDistri (None, None, 50)     10200       time_distributed_11[0][0]        
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_12[0][0]        
                                                                 dropout_16[0][0]                 
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, None, 358)    0           concatenate_6[0][0]              
__________________________________________________________________________________________________
bidirectional_18 (Bidirectional (None, None, 200)    367200      dropout_17[0][0]                 
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, None, 200)    0           bidirectional_18[0][0]           
__________________________________________________________________________________________________
dense_11 (Dense)                (None, None, 100)    20100       dropout_18[0][0]                 
__________________________________________________________________________________________________
dense_12 (Dense)                (None, None, 18)     1818        dense_11[0][0]                   
__________________________________________________________________________________________________
chain_crf_6 (ChainCRF)          (None, None, 18)     360         dense_12[0][0]                   
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 82s 219ms/step - loss: 46.9395
	f1 (micro): 87.59
Epoch 2/100

376/376 [==============================] - 69s 185ms/step - loss: 45.8823
	f1 (micro): 91.43
Epoch 3/100

376/376 [==============================] - 69s 184ms/step - loss: 44.7410
	f1 (micro): 94.50
Epoch 4/100

376/376 [==============================] - 70s 185ms/step - loss: 43.8718
	f1 (micro): 95.22
Epoch 5/100

376/376 [==============================] - 69s 183ms/step - loss: 43.7925
	f1 (micro): 95.30
Epoch 6/100

376/376 [==============================] - 69s 183ms/step - loss: 44.6791
	f1 (micro): 95.84
Epoch 7/100

376/376 [==============================] - 68s 182ms/step - loss: 43.3331
	f1 (micro): 95.50
Epoch 8/100

376/376 [==============================] - 70s 187ms/step - loss: 44.5300
	f1 (micro): 95.88
Epoch 9/100

376/376 [==============================] - 70s 186ms/step - loss: 43.8425
	f1 (micro): 95.92
Epoch 10/100

376/376 [==============================] - 69s 184ms/step - loss: 43.5343
	f1 (micro): 95.67
Epoch 11/100

376/376 [==============================] - 69s 183ms/step - loss: 44.0759
	f1 (micro): 96.04
Epoch 12/100

376/376 [==============================] - 69s 184ms/step - loss: 43.8746
	f1 (micro): 96.21
Epoch 13/100

376/376 [==============================] - 69s 182ms/step - loss: 43.7305
	f1 (micro): 96.17
Epoch 14/100

376/376 [==============================] - 68s 182ms/step - loss: 43.7503
	f1 (micro): 95.71
Epoch 15/100

376/376 [==============================] - 69s 183ms/step - loss: 43.9487
	f1 (micro): 96.42
Epoch 16/100

376/376 [==============================] - 68s 181ms/step - loss: 42.9680
	f1 (micro): 96.54
Epoch 17/100

376/376 [==============================] - 68s 182ms/step - loss: 44.2340
	f1 (micro): 96.63
Epoch 18/100

376/376 [==============================] - 69s 183ms/step - loss: 43.5741
	f1 (micro): 96.67
Epoch 19/100

376/376 [==============================] - 69s 183ms/step - loss: 43.2815
	f1 (micro): 96.33
Epoch 20/100

376/376 [==============================] - 69s 184ms/step - loss: 43.5929
	f1 (micro): 96.54
Epoch 21/100

376/376 [==============================] - 69s 184ms/step - loss: 44.0730
	f1 (micro): 96.59
Epoch 22/100

376/376 [==============================] - 70s 186ms/step - loss: 43.4857
	f1 (micro): 96.59
Epoch 23/100

376/376 [==============================] - 70s 187ms/step - loss: 43.5831
	f1 (micro): 96.67
Epoch 24/100

376/376 [==============================] - 69s 183ms/step - loss: 42.7962
	f1 (micro): 96.63
Epoch 25/100

376/376 [==============================] - 69s 184ms/step - loss: 43.3368
	f1 (micro): 96.38
Epoch 26/100

376/376 [==============================] - 69s 182ms/step - loss: 43.4169
	f1 (micro): 96.75
Epoch 27/100

376/376 [==============================] - 68s 182ms/step - loss: 43.1654
	f1 (micro): 96.84
Epoch 28/100

376/376 [==============================] - 70s 185ms/step - loss: 44.7073
	f1 (micro): 96.75
Epoch 29/100

376/376 [==============================] - 68s 181ms/step - loss: 43.6167
	f1 (micro): 96.63
Epoch 30/100

376/376 [==============================] - 68s 181ms/step - loss: 43.1214
	f1 (micro): 97.01
Epoch 31/100

376/376 [==============================] - 69s 184ms/step - loss: 42.7729
	f1 (micro): 96.59
Epoch 32/100

376/376 [==============================] - 70s 187ms/step - loss: 44.3929
	f1 (micro): 96.83
Epoch 33/100

376/376 [==============================] - 70s 186ms/step - loss: 43.3726
	f1 (micro): 97.00
Epoch 34/100

376/376 [==============================] - 70s 186ms/step - loss: 43.0703
	f1 (micro): 96.75
Epoch 35/100

376/376 [==============================] - 70s 186ms/step - loss: 43.9556
	f1 (micro): 96.67

------------------------ fold 6--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_13 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_14 (TimeDistri (None, None, 50)     10200       time_distributed_13[0][0]        
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_14[0][0]        
                                                                 dropout_19[0][0]                 
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, None, 358)    0           concatenate_7[0][0]              
__________________________________________________________________________________________________
bidirectional_21 (Bidirectional (None, None, 200)    367200      dropout_20[0][0]                 
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, None, 200)    0           bidirectional_21[0][0]           
__________________________________________________________________________________________________
dense_13 (Dense)                (None, None, 100)    20100       dropout_21[0][0]                 
__________________________________________________________________________________________________
dense_14 (Dense)                (None, None, 18)     1818        dense_13[0][0]                   
__________________________________________________________________________________________________
chain_crf_7 (ChainCRF)          (None, None, 18)     360         dense_14[0][0]                   
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 86s 230ms/step - loss: 47.7652
	f1 (micro): 87.44
Epoch 2/100

376/376 [==============================] - 69s 182ms/step - loss: 44.4350
	f1 (micro): 92.83
Epoch 3/100

376/376 [==============================] - 69s 184ms/step - loss: 45.3179
	f1 (micro): 94.29
Epoch 4/100

376/376 [==============================] - 68s 182ms/step - loss: 44.3416
	f1 (micro): 94.83
Epoch 5/100

376/376 [==============================] - 69s 183ms/step - loss: 44.5440
	f1 (micro): 95.21
Epoch 6/100

376/376 [==============================] - 69s 184ms/step - loss: 43.8047
	f1 (micro): 95.05
Epoch 7/100

376/376 [==============================] - 69s 182ms/step - loss: 44.3158
	f1 (micro): 95.63
Epoch 8/100

376/376 [==============================] - 68s 182ms/step - loss: 43.6932
	f1 (micro): 96.08
Epoch 9/100

376/376 [==============================] - 69s 184ms/step - loss: 44.0995
	f1 (micro): 95.96
Epoch 10/100

376/376 [==============================] - 70s 186ms/step - loss: 43.9375
	f1 (micro): 95.79
Epoch 11/100

376/376 [==============================] - 69s 184ms/step - loss: 44.5791
	f1 (micro): 96.54
Epoch 12/100

376/376 [==============================] - 68s 181ms/step - loss: 43.2069
	f1 (micro): 96.39
Epoch 13/100

376/376 [==============================] - 70s 186ms/step - loss: 43.8490
	f1 (micro): 95.88
Epoch 14/100

376/376 [==============================] - 70s 187ms/step - loss: 42.9247
	f1 (micro): 95.71
Epoch 15/100

376/376 [==============================] - 70s 186ms/step - loss: 43.8337
	f1 (micro): 96.09
Epoch 16/100

376/376 [==============================] - 71s 188ms/step - loss: 43.6410
	f1 (micro): 96.33

------------------------ fold 7--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_15 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_16 (TimeDistri (None, None, 50)     10200       time_distributed_15[0][0]        
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_16[0][0]        
                                                                 dropout_22[0][0]                 
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, None, 358)    0           concatenate_8[0][0]              
__________________________________________________________________________________________________
bidirectional_24 (Bidirectional (None, None, 200)    367200      dropout_23[0][0]                 
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, None, 200)    0           bidirectional_24[0][0]           
__________________________________________________________________________________________________
dense_15 (Dense)                (None, None, 100)    20100       dropout_24[0][0]                 
__________________________________________________________________________________________________
dense_16 (Dense)                (None, None, 18)     1818        dense_15[0][0]                   
__________________________________________________________________________________________________
chain_crf_8 (ChainCRF)          (None, None, 18)     360         dense_16[0][0]                   
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 87s 232ms/step - loss: 47.2796
	f1 (micro): 87.43
Epoch 2/100

376/376 [==============================] - 71s 188ms/step - loss: 44.9435
	f1 (micro): 92.84
Epoch 3/100

376/376 [==============================] - 69s 184ms/step - loss: 43.8261
	f1 (micro): 93.87
Epoch 4/100

376/376 [==============================] - 70s 185ms/step - loss: 44.3106
	f1 (micro): 94.12
Epoch 5/100

376/376 [==============================] - 70s 186ms/step - loss: 44.4837
	f1 (micro): 95.28
Epoch 6/100

376/376 [==============================] - 69s 183ms/step - loss: 43.6062
	f1 (micro): 95.91
Epoch 7/100

376/376 [==============================] - 69s 182ms/step - loss: 44.0767
	f1 (micro): 96.25
Epoch 8/100

376/376 [==============================] - 68s 182ms/step - loss: 43.4552
	f1 (micro): 96.58
Epoch 9/100

376/376 [==============================] - 69s 183ms/step - loss: 43.8346
	f1 (micro): 96.04
Epoch 10/100

376/376 [==============================] - 69s 183ms/step - loss: 43.1242
	f1 (micro): 96.37
Epoch 11/100

376/376 [==============================] - 68s 182ms/step - loss: 43.6990
	f1 (micro): 96.33
Epoch 12/100

376/376 [==============================] - 69s 184ms/step - loss: 43.2964
	f1 (micro): 96.37
Epoch 13/100

376/376 [==============================] - 70s 185ms/step - loss: 44.8283
	f1 (micro): 96.17

------------------------ fold 8--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_17 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_18 (TimeDistri (None, None, 50)     10200       time_distributed_17[0][0]        
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_18[0][0]        
                                                                 dropout_25[0][0]                 
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, None, 358)    0           concatenate_9[0][0]              
__________________________________________________________________________________________________
bidirectional_27 (Bidirectional (None, None, 200)    367200      dropout_26[0][0]                 
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, None, 200)    0           bidirectional_27[0][0]           
__________________________________________________________________________________________________
dense_17 (Dense)                (None, None, 100)    20100       dropout_27[0][0]                 
__________________________________________________________________________________________________
dense_18 (Dense)                (None, None, 18)     1818        dense_17[0][0]                   
__________________________________________________________________________________________________
chain_crf_9 (ChainCRF)          (None, None, 18)     360         dense_18[0][0]                   
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

376/376 [==============================] - 84s 224ms/step - loss: 46.8710
	f1 (micro): 84.64
Epoch 2/100

376/376 [==============================] - 70s 186ms/step - loss: 45.3494
	f1 (micro): 92.99
Epoch 3/100

376/376 [==============================] - 69s 183ms/step - loss: 44.2082
	f1 (micro): 94.71
Epoch 4/100

376/376 [==============================] - 69s 185ms/step - loss: 44.5810
	f1 (micro): 94.83
Epoch 5/100

376/376 [==============================] - 70s 187ms/step - loss: 43.9260
	f1 (micro): 95.42
Epoch 6/100

376/376 [==============================] - 69s 184ms/step - loss: 44.0096
	f1 (micro): 95.61
Epoch 7/100

376/376 [==============================] - 68s 181ms/step - loss: 43.5470
	f1 (micro): 95.58
Epoch 8/100

376/376 [==============================] - 69s 184ms/step - loss: 43.8560
	f1 (micro): 95.83
Epoch 9/100

376/376 [==============================] - 70s 185ms/step - loss: 43.4154
	f1 (micro): 95.86
Epoch 10/100

376/376 [==============================] - 69s 184ms/step - loss: 44.1044
	f1 (micro): 95.83
Epoch 11/100

376/376 [==============================] - 69s 184ms/step - loss: 43.3774
	f1 (micro): 96.20
Epoch 12/100

376/376 [==============================] - 70s 187ms/step - loss: 43.9835
	f1 (micro): 96.00
Epoch 13/100

376/376 [==============================] - 69s 183ms/step - loss: 43.5330
	f1 (micro): 96.67
Epoch 14/100

376/376 [==============================] - 69s 183ms/step - loss: 43.4517
	f1 (micro): 96.17
Epoch 15/100

376/376 [==============================] - 69s 184ms/step - loss: 43.7283
	f1 (micro): 96.51
Epoch 16/100

376/376 [==============================] - 69s 184ms/step - loss: 43.4463
	f1 (micro): 96.08
Epoch 17/100

376/376 [==============================] - 70s 186ms/step - loss: 43.2466
	f1 (micro): 96.51
Epoch 18/100

376/376 [==============================] - 70s 185ms/step - loss: 44.1646
	f1 (micro): 97.01
Epoch 19/100

376/376 [==============================] - 69s 182ms/step - loss: 43.7926
	f1 (micro): 96.59
Epoch 20/100

376/376 [==============================] - 69s 184ms/step - loss: 43.4776
	f1 (micro): 97.17
Epoch 21/100

376/376 [==============================] - 69s 183ms/step - loss: 43.5788
	f1 (micro): 97.04
Epoch 22/100

376/376 [==============================] - 71s 189ms/step - loss: 43.9133
	f1 (micro): 96.88
Epoch 23/100

376/376 [==============================] - 69s 184ms/step - loss: 44.2145
	f1 (micro): 96.88
Epoch 24/100

376/376 [==============================] - 70s 186ms/step - loss: 43.1012
	f1 (micro): 97.09
Epoch 25/100

376/376 [==============================] - 70s 187ms/step - loss: 43.6904
	f1 (micro): 96.88

------------------------ fold 9--------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
features_input (InputLayer)     (None, None, 4)      0                                            
__________________________________________________________________________________________________
char_input (InputLayer)         (None, None, 30)     0                                            
__________________________________________________________________________________________________
features_embedding_td (TimeDist (None, None, 4, 4)   196         features_input[0][0]             
__________________________________________________________________________________________________
time_distributed_19 (TimeDistri (None, None, 30, 25) 3050        char_input[0][0]                 
__________________________________________________________________________________________________
features_embedding_td_2 (TimeDi (None, None, 8)      288         features_embedding_td[0][0]      
__________________________________________________________________________________________________
word_input (InputLayer)         (None, None, 300)    0                                            
__________________________________________________________________________________________________
time_distributed_20 (TimeDistri (None, None, 50)     10200       time_distributed_19[0][0]        
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, None, 8)      0           features_embedding_td_2[0][0]    
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, None, 358)    0           word_input[0][0]                 
                                                                 time_distributed_20[0][0]        
                                                                 dropout_28[0][0]                 
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, None, 358)    0           concatenate_10[0][0]             
__________________________________________________________________________________________________
bidirectional_30 (Bidirectional (None, None, 200)    367200      dropout_29[0][0]                 
__________________________________________________________________________________________________
dropout_30 (Dropout)            (None, None, 200)    0           bidirectional_30[0][0]           
__________________________________________________________________________________________________
dense_19 (Dense)                (None, None, 100)    20100       dropout_30[0][0]                 
__________________________________________________________________________________________________
dense_20 (Dense)                (None, None, 18)     1818        dense_19[0][0]                   
__________________________________________________________________________________________________
chain_crf_10 (ChainCRF)         (None, None, 18)     360         dense_20[0][0]                   
==================================================================================================
Total params: 403,212
Trainable params: 403,212
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100


376/376 [==============================] - 89s 237ms/step - loss: 46.3067
	f1 (micro): 86.27
Epoch 2/100

376/376 [==============================] - 69s 183ms/step - loss: 44.5615
	f1 (micro): 92.50
Epoch 3/100

376/376 [==============================] - 69s 183ms/step - loss: 44.3116
	f1 (micro): 94.39
Epoch 4/100

376/376 [==============================] - 69s 184ms/step - loss: 44.6237
	f1 (micro): 94.80
Epoch 5/100

376/376 [==============================] - 70s 186ms/step - loss: 43.9648
	f1 (micro): 95.25
Epoch 6/100

376/376 [==============================] - 70s 186ms/step - loss: 43.9898
	f1 (micro): 95.62
Epoch 7/100

376/376 [==============================] - 70s 185ms/step - loss: 43.4923
	f1 (micro): 95.51
Epoch 8/100

376/376 [==============================] - 69s 184ms/step - loss: 43.7406
	f1 (micro): 95.91
Epoch 9/100

376/376 [==============================] - 69s 183ms/step - loss: 43.4793
	f1 (micro): 95.91
Epoch 10/100

376/376 [==============================] - 68s 182ms/step - loss: 43.5049
	f1 (micro): 96.21
Epoch 11/100

376/376 [==============================] - 69s 184ms/step - loss: 43.6600
	f1 (micro): 95.71
Epoch 12/100

376/376 [==============================] - 69s 183ms/step - loss: 44.1950
	f1 (micro): 96.25
Epoch 13/100

376/376 [==============================] - 68s 182ms/step - loss: 43.5319
	f1 (micro): 96.37
Epoch 14/100

376/376 [==============================] - 70s 185ms/step - loss: 43.5870
	f1 (micro): 96.92
Epoch 15/100

376/376 [==============================] - 69s 184ms/step - loss: 44.0912
	f1 (micro): 96.67
Epoch 16/100

376/376 [==============================] - 69s 184ms/step - loss: 43.3682
	f1 (micro): 96.55
Epoch 17/100

376/376 [==============================] - 69s 184ms/step - loss: 43.6482
	f1 (micro): 96.54
Epoch 18/100

376/376 [==============================] - 70s 185ms/step - loss: 44.5256
	f1 (micro): 96.67
Epoch 19/100

376/376 [==============================] - 69s 183ms/step - loss: 43.9223
	f1 (micro): 96.62
training runtime: 15652.725 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
	f1 (micro): 96.23
                  precision    recall  f1-score   support

        <doping>     0.8621    0.8621    0.8621        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9748    0.9794    0.9771       631
          <name>     0.9611    0.9665    0.9638       179
         <shape>     0.9861    0.9467    0.9660        75
     <substrate>     0.8000    1.0000    0.8889         4
         <value>     0.9552    0.9505    0.9529       202
      <variable>     0.9849    0.9899    0.9874       198

all (micro avg.)     0.9610    0.9637    0.9623      1379


------------------------ fold 1 --------------------------------------
	f1 (micro): 96.32
                  precision    recall  f1-score   support

        <doping>     0.8571    0.8966    0.8764        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9779    0.9810    0.9794       631
          <name>     0.9665    0.9665    0.9665       179
         <shape>     0.9103    0.9467    0.9281        75
     <substrate>     0.8000    1.0000    0.8889         4
         <value>     0.9698    0.9554    0.9626       202
      <variable>     0.9899    0.9949    0.9924       198

all (micro avg.)     0.9584    0.9681    0.9632      1379


------------------------ fold 2 --------------------------------------
	f1 (micro): 96.31
                  precision    recall  f1-score   support

        <doping>     0.8556    0.8851    0.8701        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9841    0.9794    0.9817       631
          <name>     0.9613    0.9721    0.9667       179
         <shape>     0.9600    0.9600    0.9600        75
     <substrate>     0.5000    0.7500    0.6000         4
         <value>     0.9320    0.9505    0.9412       202
      <variable>     0.9849    0.9899    0.9874       198

all (micro avg.)     0.9603    0.9659    0.9631      1379


------------------------ fold 3 --------------------------------------
	f1 (micro): 96.42
                  precision    recall  f1-score   support

        <doping>     0.8636    0.8736    0.8686        87
   <fabrication>     0.2500    0.3333    0.2857         3
       <formula>     0.9780    0.9842    0.9810       631
          <name>     0.9553    0.9553    0.9553       179
         <shape>     0.9730    0.9600    0.9664        75
     <substrate>     0.4444    1.0000    0.6154         4
         <value>     0.9602    0.9554    0.9578       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9611    0.9674    0.9642      1379


------------------------ fold 4 --------------------------------------
	f1 (micro): 96.14
                  precision    recall  f1-score   support

        <doping>     0.8427    0.8621    0.8523        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9763    0.9794    0.9778       631
          <name>     0.9508    0.9721    0.9613       179
         <shape>     0.9861    0.9467    0.9660        75
     <substrate>     0.5714    1.0000    0.7273         4
         <value>     0.9415    0.9554    0.9484       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9576    0.9652    0.9614      1379


------------------------ fold 5 --------------------------------------
	f1 (micro): 96.06
                  precision    recall  f1-score   support

        <doping>     0.8706    0.8506    0.8605        87
   <fabrication>     0.2000    0.3333    0.2500         3
       <formula>     0.9778    0.9762    0.9770       631
          <name>     0.9412    0.9832    0.9617       179
         <shape>     0.9595    0.9467    0.9530        75
     <substrate>     0.4286    0.7500    0.5455         4
         <value>     0.9552    0.9505    0.9529       202
      <variable>     0.9849    0.9899    0.9874       198

all (micro avg.)     0.9575    0.9637    0.9606      1379


------------------------ fold 6 --------------------------------------
	f1 (micro): 96.29
                  precision    recall  f1-score   support

        <doping>     0.8280    0.8851    0.8556        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9779    0.9810    0.9794       631
          <name>     0.9457    0.9721    0.9587       179
         <shape>     0.9726    0.9467    0.9595        75
     <substrate>     0.5714    1.0000    0.7273         4
         <value>     0.9604    0.9604    0.9604       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9577    0.9681    0.9629      1379


------------------------ fold 7 --------------------------------------
	f1 (micro): 96.21
                  precision    recall  f1-score   support

        <doping>     0.8876    0.9080    0.8977        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9717    0.9794    0.9755       631
          <name>     0.9721    0.9721    0.9721       179
         <shape>     0.9342    0.9467    0.9404        75
     <substrate>     0.4286    0.7500    0.5455         4
         <value>     0.9552    0.9505    0.9529       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9576    0.9666    0.9621      1379


------------------------ fold 8 --------------------------------------
	f1 (micro): 96.32
                  precision    recall  f1-score   support

        <doping>     0.8261    0.8736    0.8492        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9779    0.9826    0.9802       631
          <name>     0.9448    0.9553    0.9500       179
         <shape>     0.9474    0.9600    0.9536        75
     <substrate>     0.6667    1.0000    0.8000         4
         <value>     0.9701    0.9653    0.9677       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9590    0.9674    0.9632      1379


------------------------ fold 9 --------------------------------------
	f1 (micro): 96.10
                  precision    recall  f1-score   support

        <doping>     0.8105    0.8851    0.8462        87
   <fabrication>     0.0000    0.0000    0.0000         3
       <formula>     0.9731    0.9762    0.9747       631
          <name>     0.9663    0.9609    0.9636       179
         <shape>     0.9733    0.9733    0.9733        75
     <substrate>     0.6667    1.0000    0.8000         4
         <value>     0.9461    0.9554    0.9507       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9569    0.9652    0.9610      1379

----------------------------------------------------------------------

** Worst ** model scores - run 5
                  precision    recall  f1-score   support

        <doping>     0.8706    0.8506    0.8605        87
   <fabrication>     0.2000    0.3333    0.2500         3
       <formula>     0.9778    0.9762    0.9770       631
          <name>     0.9412    0.9832    0.9617       179
         <shape>     0.9595    0.9467    0.9530        75
     <substrate>     0.4286    0.7500    0.5455         4
         <value>     0.9552    0.9505    0.9529       202
      <variable>     0.9849    0.9899    0.9874       198

all (micro avg.)     0.9575    0.9637    0.9606      1379


** Best ** model scores - run 3
                  precision    recall  f1-score   support

        <doping>     0.8636    0.8736    0.8686        87
   <fabrication>     0.2500    0.3333    0.2857         3
       <formula>     0.9780    0.9842    0.9810       631
          <name>     0.9553    0.9553    0.9553       179
         <shape>     0.9730    0.9600    0.9664        75
     <substrate>     0.4444    1.0000    0.6154         4
         <value>     0.9602    0.9554    0.9578       202
      <variable>     0.9899    0.9899    0.9899       198

all (micro avg.)     0.9611    0.9674    0.9642      1379

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

        <doping>     0.8504    0.8782    0.8638        87
   <fabrication>     0.0450    0.0667    0.0536         3
       <formula>     0.9769    0.9799    0.9784       631
          <name>     0.9565    0.9676    0.9620       179
         <shape>     0.9602    0.9533    0.9566        75
     <substrate>     0.5878    0.9250    0.7139         4
         <value>     0.9546    0.9550    0.9547       202
      <variable>     0.9884    0.9904    0.9894       198

all (micro avg.)     0.9587    0.9661    0.9624          

model config file saved
preprocessor saved
model saved
