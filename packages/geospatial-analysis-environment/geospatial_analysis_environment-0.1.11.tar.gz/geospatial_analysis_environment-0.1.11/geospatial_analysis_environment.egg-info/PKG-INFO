Metadata-Version: 2.2
Name: geospatial-analysis-environment
Version: 0.1.11
Summary: Geospatial analysis environment.
Author-email: Chris Lowrie <lowriechris779@gmail.com>
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: <3.13,>=3.12
Description-Content-Type: text/markdown
Requires-Dist: dask[array,dataframe,diagnostics,distributed]>=2025.2.0
Requires-Dist: duckdb>=1.2.0
Requires-Dist: fastparquet>=2024.11.0
Requires-Dist: fiona>=1.10.1
Requires-Dist: fsspec>=2025.2.0
Requires-Dist: gcsfs>=2025.2.0
Requires-Dist: geopandas>=1.0.1
Requires-Dist: google-cloud-storage>=3.0.0
Requires-Dist: h5netcdf>=1.5.0
Requires-Dist: joblib>=1.4.2
Requires-Dist: matplotlib>=3.10.0
Requires-Dist: memory-profiler>=0.61.0
Requires-Dist: numba==0.60.0
Requires-Dist: numpy>=2.0.2
Requires-Dist: odc-geo>=0.4.9.post0
Requires-Dist: pandas>=2.2.3
Requires-Dist: pyarrow>=19.0.0
Requires-Dist: pytest>=8.3.4
Requires-Dist: rasterio>=1.4.3
Requires-Dist: rioxarray>=0.18.2
Requires-Dist: s2sphere>=0.2.5
Requires-Dist: s3fs>=2025.2.0
Requires-Dist: toml>=0.10.2
Requires-Dist: tqdm>=4.67.1
Requires-Dist: xarray>=2025.1.2
Requires-Dist: xarray-spatial>=0.4.0
Requires-Dist: zarr>=3.0.3

# Spatial Analysis Environment

This repo abstracts the basics of a spatial analysis environment, so it can be used consistently across microservices.

A slightly weird thing right now:
- We want to use conda for installation, because it helps manage a lot of the dependencies (GDAL)
- But we can't use conda for publishing, because the path to get on conda-forge seems like a pain and we haven't prioritized it. Eventually we'll use pixi, but pixi build is still in development.
- So we're using `uv` to publish, and that introduces some dependency mismatches.  We can see what those are with the `create-mismatch-report` target.  So far they have been minor.

## Environments

The `environments` directory contains the base environment and any other environments that are needed.

The `base` environment is the core dependencies for all later tooling and environments.

The `analysis` environment is used for later tooling that is specific to analysis (like RasterOps and VectorOps).

The `jupyter` environment is used for the Jupyter notebook and includes RasterOps and VectorOps.

The `pmtiles` environment is used for the PMTiles tooling.

## Usage

### Adding a new dependency

When adding a new dependency to the project:

1. Add the package to `environments/base/base.yml`:
```yaml
dependencies:
  - new-package>=1.0.0
```

2. Add the same package to `pyproject.toml`:
```toml
dependencies = [
    "new-package>=1.0.0",
]
```

3. Update the lock files:
```bash
make lock
```

4. Review the mismatch report at `version_info/mismatch_report.txt` to ensure version alignment between conda and uv

5. Test the environment:
```bash
make test-conda
```

Note: Package names might differ slightly between conda and pip (e.g., `memory_profiler` vs `memory-profiler`). Check both repositories if you encounter installation issues.

### Publishing
The package can be published to PyPI using the following workflow:

```bash
# First build the publisher container
make publisher-base

# Create a new lock file if dependencies have changed
make lock

# Publish to PyPI (requires UV_PUBLISH_TOKEN in .env.publish)
make publish
```

Note: Before publishing, ensure you have created a `.env.publish` file with your PyPI token:
```
UV_PUBLISH_TOKEN=your_token_here
```

## Deploying a Jupyter Notebook to Nautilus

### Prerequisites

1. Install `helm` (On MacOSX):
```bash
brew install helm
```
See https://helm.sh/docs/intro/install/ for other systems.

2. Configure AWS credentials:
Create a file named `.env.s3` with your Nautilus Cept S3 credentials:
```
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_ENDPOINT_URL=your_endpoint_url
```

### Deployment

Create a deployment with a pod, ingress, and persistent volume unique to you:
```bash
make jupyter-deploy
```

Release resources when you're done:
```bash
make jupyter-teardown
```
