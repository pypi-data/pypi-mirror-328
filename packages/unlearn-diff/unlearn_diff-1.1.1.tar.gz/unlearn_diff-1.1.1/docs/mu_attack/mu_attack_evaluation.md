### Evaluation:

In this section, we assess the performance and robustness of the results generated by the attack algorithms

#### **Running the Evaluation Framework**

Create a file, eg, `evaluate.py` and use examples and modify your configs to run the file.  

**Example Code**

```python
from evaluation.evaluators.asr import ASREvaluator
from evaluation.evaluators.clip_score import ClipScoreEvaluator
from evaluation.evaluators.mu_attack_fid import FIDEvaluator
from mu_attack.configs.evaluation import attack_evaluation_config


def main():
    # Initialize the configuration
    config = attack_evaluation_config
    config.asr.root = "/home/ubuntu/Projects/Palistha/unlearn_diff_attack/results/hard_prompt_esd_nudity_P4D_concept_ablation/P4d"
    config.asr.root_no_attack = "/home/ubuntu/Projects/Palistha/unlearn_diff_attack/results/no_attack_esd_nudity/NoAttackEsdNudity"
    config.clip.devices = "0"
    config.clip.image_path = "/home/ubuntu/Projects/Palistha/unlearn_diff_attack/results/hard_prompt_esd_nudity_P4D_concept_ablation/P4d/images"
    config.clip.log_path = "/home/ubuntu/Projects/Palistha/unlearn_diff_attack/results/hard_prompt_esd_nudity_P4D_concept_ablation/P4d/log.json"
    config.fid.ref_batch_path = "/home/ubuntu/Projects/Palistha/unlearn_diff_attack/results/hard_prompt_esd_nudity_P4D_concept_ablation/P4d/images"
    config.fid.sample_batch_path = "/home/ubuntu/Projects/balaram/unlearn_diff_attack/outputs/dataset/i2p_nude/imgs"

    # Common output path
    config.output_path = "/home/ubuntu/Projects/Palistha/unlearn_diff_attack/results/evaluation/results.json"

    # Initialize and run the ASR evaluator
    asr_evaluator = ASREvaluator(
        config = attack_evaluation_config,
        root=config.asr.root,
        root_no_attack=config.asr.root_no_attack,
        output_path=config.output_path
    )
    print("Running ASR Evaluator...")
    asr_evaluator.run()

    # Initialize and run the CLIP Score evaluator
    clip_evaluator = ClipScoreEvaluator(
        config = attack_evaluation_config,
        image_path=config.clip.image_path,
        log_path=config.clip.log_path,
        output_path=config.output_path,
        devices = config.clip.devices
    )
    print("Running CLIP Score Evaluator...")
    clip_evaluator.run()

    # Initialize and run the FID evaluator
    fid_evaluator = FIDEvaluator(
        config = attack_evaluation_config,
        ref_batch_path=config.fid.ref_batch_path,
        sample_batch_path=config.fid.sample_batch_path,
        output_path=config.output_path
    )
    print("Running FID Evaluator...")
    fid_evaluator.run()


if __name__ == "__main__":
    main()


```

**Running the Training Script in Offline Mode**

```bash
WANDB_MODE=offline python evaluate.py
```

**How It Works** 
* Default Values: The script first loads default values from the evluation config file as in configs section.

* Parameter Overrides: Any parameters passed directly to the algorithm, overrides these configs.

* Final Configuration: The script merges the configs and convert them into dictionary to proceed with the evaluation. 


**Evaluation Metrics:**

* Attack Succes Rate (ASR)

* Fr√©chet inception distance(FID): evaluate distributional quality of image generations, lower is better.

* CLIP score : measure contextual alignment with prompt descriptions, higher is better.


**Configuration File Structure for Evaluator**

* ASR Evaluator Configuration

    - root: Directory containing results with attack.
    - root-no-attack: Directory containing results without attack.

* Clip Evaluator Configuration

    - image_path: Path to the directory containing generated images to evaluate.
    - devices: Device ID(s) to use for evaluation. Example: "0" for the first GPU or "0,1" for multiple GPUs.
    - log_path: Path to the log file containing prompt for the generated images.
    - model_name_or_path: Path or model name for the pre-trained CLIP model. Default is "openai/clip-vit-base-patch32".

* FID Evaluator Configuration

    - ref_batch_path: Path to the directory containing reference images.
    - sample_batch_path: Path to the directory containing generated/sample images.

* Global Configuration

    - output_path: Path to save the evaluation results as a JSON file.


