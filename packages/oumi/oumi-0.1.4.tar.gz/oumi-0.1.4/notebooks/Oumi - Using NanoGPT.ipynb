{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"align-center\">\n",
    "<a href=\"https://oumi.ai/\"><img src=\"https://oumi.ai/docs/en/latest/_static/logo/header_logo.png\" height=\"200\"></a>\n",
    "\n",
    "[![Documentation](https://img.shields.io/badge/Documentation-latest-blue.svg)](https://oumi.ai/docs/en/latest/index.html)\n",
    "[![Discord](https://img.shields.io/discord/1286348126797430814?label=Discord)](https://discord.gg/oumi)\n",
    "[![GitHub Repo stars](https://img.shields.io/github/stars/oumi-ai/oumi)](https://github.com/oumi-ai/oumi)\n",
    "</div>\n",
    "\n",
    "üëã Welcome to Open Universal Machine Intelligence (Oumi)!\n",
    "\n",
    "üöÄ Oumi is a fully open-source platform that streamlines the entire lifecycle of foundation models - from [data preparation](https://oumi.ai/docs/en/latest/resources/datasets/datasets.html) and [training](hhttps://oumi.ai/docs/en/latest/user_guides/train/train.html) to [evaluation](https://oumi.ai/docs/en/latest/user_guides/evaluate/evaluate.html) and [deployment](https://oumi.ai/docs/en/latest/user_guides/launch/launch.html). Whether you're developing on a laptop, launching large scale experiments on a cluster, or deploying models in production, Oumi provides the tools and workflows you need.\n",
    "\n",
    "ü§ù Make sure to join our [Discord community](https://discord.gg/oumi) to get help, share your experiences, and contribute to the project! If you are interested in joining one of the community's open-science efforts, check out our [open collaboration](https://oumi.ai/community) page.\n",
    "\n",
    "‚≠ê If you like Oumi and you would like to support it, please give it a star on [GitHub](https://github.com/oumi-ai/oumi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting NanoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "The goal of this notebook is to show how to use a custom model with Oumi.\n",
    "\n",
    "In this case, we will adapt [nanogpt](https://github.com/karpathy/nanoGPT), and train it with the HuggingFace training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes that you have already installed the `oumi` package. If you haven't, you can install it by running `!pip install oumi`.\n",
    "\n",
    "We start then by cloning the nanoGPT repository, and adding nanoGPT to our python path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_folder = Path(\"/tmp/oumi/nanoGPT\")\n",
    "\n",
    "# Clone the nanoGPT repo\n",
    "if not module_folder.is_dir():\n",
    "    module_folder.mkdir(parents=True, exist_ok=True)\n",
    "    !git clone https://github.com/karpathy/nanoGPT {module_folder}\n",
    "else:\n",
    "    print(\"nanoGPT already cloned!\")\n",
    "\n",
    "sys.path.append(str(module_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we install the required dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U -q tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting nanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from model import GPT, GPTConfig  # import from ~/nanoGPT/model.py\n",
    "\n",
    "from oumi.core import registry\n",
    "\n",
    "\n",
    "@registry.register(\"oumi-nanoGPT\", registry_type=registry.RegistryType.MODEL)\n",
    "class OumiNanoGPT(GPT):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initializes an instance of the class.\"\"\"\n",
    "        gpt_config = GPTConfig()\n",
    "        gpt_config.bias = False\n",
    "\n",
    "        super().__init__(gpt_config)\n",
    "\n",
    "    def forward(self, input_ids, labels=None, attention_mask=None):\n",
    "        \"\"\"Performs the forward pass of the model.\"\"\"\n",
    "        # Update the return format to be compatible with our Trainer.\n",
    "        logits, loss = super().forward(idx=input_ids, targets=labels)\n",
    "        outputs = {\"logits\": logits}\n",
    "        if loss:\n",
    "            outputs[\"loss\"] = loss\n",
    "        return outputs\n",
    "\n",
    "    def criterion(self):\n",
    "        \"\"\"Returns the criterion used for calculating the loss.\"\"\"\n",
    "        return F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Ok now we are ready to train our model! we can start from the default gpt2 config, and edit as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oumi\n",
    "from oumi.core.configs import TrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from the default GPT-2 config\n",
    "config_path = \"../configs/recipes/gpt2/pretraining/mac_train.yaml\"\n",
    "config = TrainingConfig.from_yaml(config_path)\n",
    "\n",
    "config.training.output_dir = \"nanogpt_tutorial\"\n",
    "# Update to use our newly registered nanoGPT model\n",
    "config.model.model_name = \"oumi-nanoGPT\"  # needs to match the registered model name\n",
    "# We do not have a custom tokenizer, but we can use the GPT-2 tokenizer from HuggingFace\n",
    "config.model.tokenizer_name = \"gpt2\"\n",
    "# These are needed specifically to get nanoGPT to work, and likely aren't needed for\n",
    "# other custom models.\n",
    "config.training.enable_tensorboard = False\n",
    "config.training.save_steps = 0\n",
    "config.training.save_final_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oumi.train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
