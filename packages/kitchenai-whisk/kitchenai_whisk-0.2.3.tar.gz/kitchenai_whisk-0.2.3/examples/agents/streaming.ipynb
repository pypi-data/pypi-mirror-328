{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisk.kitchenai_sdk.schema import ChatInput, ChatResponse\n",
    "from whisk.kitchenai_sdk.kitchenai import KitchenAIApp\n",
    "\n",
    "\n",
    "kitchen = KitchenAIApp(namespace=\"streaming-demo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "from llama_index.core.tools import FunctionTool\n",
    "import asyncio\n",
    "\n",
    "# Define a simple tool for demonstration\n",
    "def calculator(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Create a tool instance\n",
    "calc_tool = FunctionTool.from_defaults(fn=calculator)\n",
    "\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Non-streaming Agent\n",
    "# Create the agent with tools\n",
    "agent_b = ReActAgent.from_tools(\n",
    "    tools=[calc_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "# Streaming Agent\n",
    "    # Create the agent with streaming enabled\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=[calc_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 93610a8f-e24b-486f-b0ca-2264a2833a52. Step input: What is 121 + 8? Once you have the answer, use that number to write a story about a group of mice.\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: calculator\n",
      "Action Input: {'a': 121, 'b': 8}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 129\n",
      "\u001b[0m> Running step f7ea3041-7c02-454e-90e5-af3f6b458724. Step input: None\n",
      " 129\n",
      "\n",
      "Once upon a time, in a cozy little burrow nestled beneath a large oak tree, there lived a group of adventurous mice. The leader of the group, a wise old mouse named Whiskers, had just discovered a hidden treasure of 129 shiny acorns. Excited by their newfound wealth, the mice decided to throw a grand feast to celebrate their good fortune. As the moon rose high in the sky, the mice danced and feasted on delicious acorn treats, their tiny paws tapping to the rhythm of the night. And so, the mice lived happily ever after, their bellies full and their hearts content in their cozy burrow beneath the oak tree."
     ]
    }
   ],
   "source": [
    "response = await agent.astream_chat(\n",
    "    \"What is 121 + 8? Once you have the answer, use that number to write a\"\n",
    "    \" story about a group of mice.\"\n",
    ")\n",
    "\n",
    "response_gen = response.response_gen\n",
    "\n",
    "async for token in response.async_response_gen():\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AsyncGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kitchen.chat.handler(\"streaming-response\")\n",
    "async def streaming_response(input: ChatInput) -> AsyncGenerator[ChatResponse, None]:\n",
    "    response = await llm.astream_complete(\n",
    "        input.messages[-1].content\n",
    "    )\n",
    "\n",
    "\n",
    "    async for delta in response:\n",
    "        yield ChatResponse(content=delta.delta, role=\"assistant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down existing Whisk server...\n",
      "Whisk server stopped.\n",
      "Whisk server started on http://0.0.0.0:8000 (in background)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [690865]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57072 - \"OPTIONS /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:38258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Launch Whisk server\n",
    "from whisk.config import WhiskConfig, ServerConfig\n",
    "from whisk.router import WhiskRouter\n",
    "\n",
    "config = WhiskConfig(server=ServerConfig(type=\"fastapi\"))\n",
    "router = WhiskRouter(kitchen_app=kitchen, config=config)\n",
    "\n",
    "# Run the Whisk server in the notebook\n",
    "router.run_in_notebook(host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [690865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down existing Whisk server...\n",
      "Whisk server stopped.\n"
     ]
    }
   ],
   "source": [
    "router.stop_in_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kitchenai-whisk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
