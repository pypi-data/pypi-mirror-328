{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import rtsvg\n",
    "import re\n",
    "import shapely.affinity as affinity\n",
    "rt = rtsvg.RACETrack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def junk(min_words=16, max_words=128):\n",
    "    def makeWord(min_chars=3, max_chars=8):\n",
    "        return ''.join(random.choices(string.ascii_uppercase + string.digits, k=random.randint(min_chars,max_chars)))\n",
    "    words = []\n",
    "    for i in range(random.randint(min_words, max_words)):\n",
    "        words.append(makeWord())\n",
    "    return ' '.join(words)\n",
    "\n",
    "my_markers = ['marker1', 'marker2', 'marker3', 'marker4', 'this is a longer marker that is meant to go across lines']\n",
    "my_colors  = ['#ff0000', '#00ff00', '#0000ff', '#ffff00', '#a0a0a0']\n",
    "all_lus    = {my_markers[0]: my_colors[0], my_markers[1]: my_colors[1], my_markers[2]: my_colors[2], my_markers[3]: my_colors[3], my_markers[4]: my_colors[4]}\n",
    "my_markups = {'Ex 1': {my_markers[0]: my_colors[0], my_markers[1]: my_colors[1]},\n",
    "              'Ex 2': {my_markers[2]: my_colors[2], my_markers[0]: my_colors[0]},\n",
    "              'Ex 3': {my_markers[0]: my_colors[0], my_markers[1]: my_colors[1], my_markers[3]: my_colors[3]},\n",
    "              'Ex 4': {my_markers[2]: my_colors[2], my_markers[3]: my_colors[3]},\n",
    "              'Ex 5': {my_markers[4]: my_colors[4]}}\n",
    "def makePassage(markers):\n",
    "    _txt_= []\n",
    "    _txt_.append(junk() + ' ' +random.choice(markers) + ' ' + junk())\n",
    "    _txt_.append(random.choice(markers) + ' ' + junk(10, 12) + ' ' + random.choice(markers))\n",
    "    _txt_.append(junk(32,64))\n",
    "    _txt_.append(junk() + ' ' +random.choice(markers) + ' ' + junk(10, 12) + ' ' + random.choice(markers) + ' ' + junk(10, 12) + ' ' + random.choice(markers))\n",
    "    _txt_.append(junk(32,256))\n",
    "    _txt_.append(random.choice(markers) + ' ' + junk(10, 12) + ' ' + random.choice(markers))\n",
    "    _txt_.append(junk(32,256))\n",
    "    _txt_.append(random.choice(markers) + ' ' + junk(10, 12) + ' ' + random.choice(markers))\n",
    "    _txt_.append(junk(32,40))\n",
    "    _txt_.append(random.choice(markers) + ' ' + junk(10, 12) + ' ' + random.choice(markers))\n",
    "    return '\\n'.join(_txt_)\n",
    "\n",
    "passage = makePassage(my_markers)\n",
    "_tb_ = rt.textBlock(passage, word_wrap=True, w=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareHighlightsPixelReprs(self, \n",
    "                                highlights_dict, \n",
    "                                opacity           = 0.2,  # opacity of the highlights\n",
    "                                y_merge_threshold = 1.0,  # multiple of txt_h\n",
    "                                y_render_gap      = 2.0): # multiple of txt_h\n",
    "    y_merge_threshold *= self.txt_h\n",
    "    y_render_gap      *= self.txt_h\n",
    "    # Find all text spans first\n",
    "    location_lookups = {} # a highlight to the text spans that it covers\n",
    "    color_lookups    = {}\n",
    "    for highlighters in highlights_dict:\n",
    "        highlight_locations = list(highlights_dict[highlighters].keys())\n",
    "        for highlight_location in highlight_locations:\n",
    "            color_lookups[highlight_location] = highlights_dict[highlighters][highlight_location]\n",
    "            if highlight_location not in location_lookups:\n",
    "                location_lookups[highlight_location] = []\n",
    "                if   type(highlight_location) is tuple: location_lookups[highlight_location].append(highlight_location) # it's already a span\n",
    "                elif type(highlight_location) is str:\n",
    "                    re_match = re.findall(highlight_location,self.txt)\n",
    "                    if re_match is not None and len(re_match) > 0:\n",
    "                        for _match in re_match:\n",
    "                            if type(_match) == tuple: _match = _match[0]\n",
    "                            i = 0\n",
    "                            while i < len(self.txt) and _match in self.txt[i:]:\n",
    "                                i = self.txt.index(_match, i)\n",
    "                                j = i + len(_match)\n",
    "                                location_lookups[highlight_location].append((i,j))\n",
    "                                i = j\n",
    "                else: raise Exception('unknown highlight type: ' + str(type(highlight_location)))\n",
    "\n",
    "    _svg_ = []\n",
    "\n",
    "    # Convert to y coordinates pairs\n",
    "    y_coord_pairs = []\n",
    "    for k in location_lookups:\n",
    "        for _span_ in location_lookups[k]:\n",
    "            _poly_ = self.spanGeometry(_span_[0], _span_[1])\n",
    "            x0, y0, x1, y1 = _poly_.bounds\n",
    "            y_coord_pairs.append((y0, y1))\n",
    "    y_coord_pairs = sorted(y_coord_pairs)\n",
    "\n",
    "    # Consolidate\n",
    "    y_consolidated_pairs, i = [], 0\n",
    "    while i < len(y_coord_pairs):\n",
    "        j = i + 1\n",
    "        while j <  len(y_coord_pairs) and y_coord_pairs[j][0] - y_coord_pairs[j-1][1] < y_merge_threshold: j += 1\n",
    "        y_consolidated_pairs.append((y_coord_pairs[i][0], y_coord_pairs[j-1][1]))\n",
    "        i = j\n",
    "    #for _pair_ in y_consolidated_pairs:\n",
    "        #_x_ = random.randint(0, 128)\n",
    "        #_svg_.append(f'<line x1=\"{_x_}\" y1=\"{_pair_[0]}\" x2=\"{_x_}\" y2=\"{_pair_[1]}\" stroke=\"#ff0000\" stroke-width=\"2.0\"/>')\n",
    "        #_svg_.append(f'<line x1=\"{_x_-40}\" y1=\"{_pair_[0]}\" x2=\"{_x_+40}\" y2=\"{_pair_[0]}\" stroke=\"#ff0000\" stroke-width=\"2.0\"/>')\n",
    "        #_svg_.append(f'<line x1=\"{_x_-40}\" y1=\"{_pair_[1]}\" x2=\"{_x_+40}\" y2=\"{_pair_[1]}\" stroke=\"#ff0000\" stroke-width=\"2.0\"/>')\n",
    "\n",
    "    # Render the text in a consolidated format\n",
    "    new_y_lu   = {}\n",
    "    max_y_seen = 0\n",
    "    max_x_rendered, max_y_rendered = 128, 128\n",
    "    for _poly_ in self.geom_to_word:\n",
    "        x0, y0, x1, y1 = _poly_.bounds\n",
    "        max_y_seen     = max(max_y_seen, y1)\n",
    "        y_mid          = (y0 + y1) / 2.0\n",
    "        i              = None\n",
    "        for j in range(len(y_consolidated_pairs)):\n",
    "            if y_mid >= y_consolidated_pairs[j][0] and y_mid <= y_consolidated_pairs[j][1]: i = j\n",
    "        if i is not None:\n",
    "            rendered_so_far = 0 if y_consolidated_pairs[0][0] == 0.0 else y_render_gap\n",
    "            for j in range(0, i): rendered_so_far += y_consolidated_pairs[j][1] - y_consolidated_pairs[j][0] + y_render_gap\n",
    "            _y_ = y1 - 2*self.y_ins - y_consolidated_pairs[i][0] + rendered_so_far\n",
    "            new_y_lu[y1] = _y_\n",
    "            _svg_.append(rt.svgText(self.geom_to_word[_poly_], x0, _y_, self.txt_h))\n",
    "            if x1  > max_x_rendered: max_x_rendered = x1\n",
    "            if _y_ > max_y_rendered: max_y_rendered = _y_\n",
    "\n",
    "    if y_consolidated_pairs[-1][1] != max_y_seen: max_y_rendered += y_render_gap\n",
    "\n",
    "    # Render symbols to indicate breaks in the text\n",
    "    y_set = set()\n",
    "    for _y_ in new_y_lu: y_set.add(new_y_lu[_y_])\n",
    "    y_list = sorted(list(y_set))\n",
    "    for i in range(len(y_list) - 1):\n",
    "        if (y_list[i+1] - y_list[i]) > y_render_gap:\n",
    "            y_avg = (y_list[i] + y_list[i+1]) / 2.0\n",
    "            x     =  self.x_ins\n",
    "            d     =  f'M {x} {y_avg} '\n",
    "            count = 1\n",
    "            while x < max_x_rendered - self.txt_h:\n",
    "                x += self.txt_h\n",
    "                if count % 2 == 0: d += f'L {x} {y_avg} '\n",
    "                else:              d += f'L {x} {y_avg-self.txt_h/2.0} '\n",
    "                count += 1\n",
    "            _svg_.append(f'<path d=\"{d}\" stroke=\"#a0a0a0\" stroke-width=\"0.5\" fill=\"none\" dasharray=\"5,5\" />')\n",
    "\n",
    "    # For each highlighter, render a different highlight overlap for the consolidated text\n",
    "    svg_dict = {}\n",
    "    for highlighter in highlights_dict:\n",
    "        svg_for_this_highlighter = []\n",
    "        for _highlight_ in highlights_dict[highlighter]:\n",
    "            _color_ = highlights_dict[highlighter][_highlight_]\n",
    "            _spans_ = location_lookups[_highlight_]\n",
    "            for _span_ in _spans_:\n",
    "                _poly_ = self.spanGeometry(_span_[0], _span_[1])\n",
    "                x0, y0, x1, y1 = _poly_.bounds\n",
    "                closest_y = None\n",
    "                for _y_ in new_y_lu:\n",
    "                    if   closest_y is None: closest_y = _y_\n",
    "                    elif abs(_y_ - y1) < abs(closest_y - y1): closest_y = _y_\n",
    "                new_y = new_y_lu[closest_y]\n",
    "                _poly_translated_ = affinity.translate(_poly_, 0, new_y - y1 + 2)\n",
    "                svg_for_this_highlighter.append(f'<path d=\"{self.rt_self.shapelyPolygonToSVGPathDescription(_poly_translated_)}\" fill=\"{_color_}\" opacity=\"{opacity}\" />')\n",
    "        svg_dict[highlighter] = f'<svg x=\"0\" y=\"0\" width=\"{max_x_rendered + self.x_ins}\" height=\"{max_y_rendered + self.y_ins}\">' + \\\n",
    "                                ''.join(_svg_) + ''.join(svg_for_this_highlighter) + '</svg>'\n",
    "\n",
    "    return svg_dict\n",
    "\n",
    "my_svg_dict   = compareHighlightsPixelReprs(_tb_, my_markups)\n",
    "_example_svg_ =list(my_svg_dict.values())[0]\n",
    "w, h          = rt.__extractSVGWidthAndHeight__(_example_svg_)\n",
    "_spacer_      = rt.spacer(20, h, '#000000')\n",
    "_list_        = []\n",
    "for _svg_ in my_svg_dict.values(): \n",
    "    if len(_list_) > 0: _list_.append(_spacer_)\n",
    "    _list_.append(_svg_)\n",
    "rt.tile(_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareHighlightsPixelReprsWExtra(self, \n",
    "                                      highlights_dict, \n",
    "                                      opacity           = 0.2,  # opacity of the highlights\n",
    "                                      y_merge_threshold = 1.0,  # multiple of txt_h\n",
    "                                      y_keep            = 2.0,  # multiple of txt_h\n",
    "                                      y_render_gap      = 2.0): # multiple of txt_h\n",
    "    y_merge_threshold *= self.txt_h\n",
    "    y_keep            *= self.txt_h\n",
    "    y_render_gap      *= self.txt_h\n",
    "    # Find all text spans first\n",
    "    location_lookups = {} # a highlight to the text spans that it covers\n",
    "    color_lookups    = {}\n",
    "    for highlighters in highlights_dict:\n",
    "        highlight_locations = list(highlights_dict[highlighters].keys())\n",
    "        for highlight_location in highlight_locations:\n",
    "            color_lookups[highlight_location] = highlights_dict[highlighters][highlight_location]\n",
    "            if highlight_location not in location_lookups:\n",
    "                location_lookups[highlight_location] = []\n",
    "                if   type(highlight_location) is tuple: location_lookups[highlight_location].append(highlight_location) # it's already a span\n",
    "                elif type(highlight_location) is str:\n",
    "                    re_match = re.findall(highlight_location,self.txt)\n",
    "                    if re_match is not None and len(re_match) > 0:\n",
    "                        for _match in re_match:\n",
    "                            if type(_match) == tuple: _match = _match[0]\n",
    "                            i = 0\n",
    "                            while i < len(self.txt) and _match in self.txt[i:]:\n",
    "                                i = self.txt.index(_match, i)\n",
    "                                j = i + len(_match)\n",
    "                                location_lookups[highlight_location].append((i,j))\n",
    "                                i = j\n",
    "                else: raise Exception('unknown highlight type: ' + str(type(highlight_location)))\n",
    "\n",
    "    _svg_ = []\n",
    "\n",
    "    # Convert to y coordinates pairs\n",
    "    y_coord_pairs = []\n",
    "    for k in location_lookups:\n",
    "        for _span_ in location_lookups[k]:\n",
    "            _poly_ = self.spanGeometry(_span_[0], _span_[1])\n",
    "            x0, y0, x1, y1 = _poly_.bounds\n",
    "            y_coord_pairs.append((y0, y1))\n",
    "    y_coord_pairs = sorted(y_coord_pairs)\n",
    "\n",
    "    # Consolidate\n",
    "    y_consolidated_pairs, i = [], 0\n",
    "    while i < len(y_coord_pairs):\n",
    "        j = i + 1\n",
    "        while j <  len(y_coord_pairs) and y_coord_pairs[j][0] - y_coord_pairs[j-1][1] < y_merge_threshold: j += 1\n",
    "        y_consolidated_pairs.append((y_coord_pairs[i][0], y_coord_pairs[j-1][1]))\n",
    "        i = j\n",
    "\n",
    "    # Render the text in a consolidated format\n",
    "    new_y_lu   = {}\n",
    "    max_y_seen = 0\n",
    "    max_x_rendered, max_y_rendered = 128, 128\n",
    "    for _poly_ in self.geom_to_word:\n",
    "        x0, y0, x1, y1 = _poly_.bounds\n",
    "        max_y_seen     = max(max_y_seen, y1)\n",
    "        y_mid          = (y0 + y1) / 2.0\n",
    "        i              = None\n",
    "        for j in range(len(y_consolidated_pairs)):\n",
    "            if y_mid >= (y_consolidated_pairs[j][0] - y_keep) and y_mid <= (y_consolidated_pairs[j][1] + y_keep): i = j\n",
    "        if i is not None:\n",
    "            rendered_so_far = 0 if y_consolidated_pairs[0][0] == 0.0 else y_render_gap + y_keep\n",
    "            for j in range(0, i): rendered_so_far += y_consolidated_pairs[j][1] - y_consolidated_pairs[j][0] + y_render_gap + 2.0 * y_keep\n",
    "            _y_ = y1 - 2*self.y_ins - y_consolidated_pairs[i][0] + rendered_so_far\n",
    "            new_y_lu[y1] = _y_\n",
    "            _svg_.append(rt.svgText(self.geom_to_word[_poly_], x0, _y_, self.txt_h))\n",
    "            if x1  > max_x_rendered: max_x_rendered = x1\n",
    "            if _y_ > max_y_rendered: max_y_rendered = _y_\n",
    "\n",
    "    if y_consolidated_pairs[-1][1] != max_y_seen: max_y_rendered += y_render_gap\n",
    "\n",
    "    # Render symbols to indicate breaks in the text\n",
    "    y_set = set()\n",
    "    for _y_ in new_y_lu: y_set.add(new_y_lu[_y_])\n",
    "    y_list = sorted(list(y_set))\n",
    "    for i in range(len(y_list) - 1):\n",
    "        if (y_list[i+1] - y_list[i]) > y_render_gap:\n",
    "            y_avg = (y_list[i] + y_list[i+1]) / 2.0\n",
    "            x     =  self.x_ins\n",
    "            d     =  f'M {x} {y_avg} '\n",
    "            count = 1\n",
    "            while x < max_x_rendered - self.txt_h:\n",
    "                x += self.txt_h\n",
    "                if count % 2 == 0: d += f'L {x} {y_avg} '\n",
    "                else:              d += f'L {x} {y_avg-self.txt_h/2.0} '\n",
    "                count += 1\n",
    "            _svg_.append(f'<path d=\"{d}\" stroke=\"#a0a0a0\" stroke-width=\"0.5\" fill=\"none\" dasharray=\"5,5\" />')\n",
    "\n",
    "    # For each highlighter, render a different highlight overlap for the consolidated text\n",
    "    svg_dict = {}\n",
    "    for highlighter in highlights_dict:\n",
    "        svg_for_this_highlighter = []\n",
    "        for _highlight_ in highlights_dict[highlighter]:\n",
    "            _color_ = highlights_dict[highlighter][_highlight_]\n",
    "            _spans_ = location_lookups[_highlight_]\n",
    "            for _span_ in _spans_:\n",
    "                _poly_ = self.spanGeometry(_span_[0], _span_[1])\n",
    "                x0, y0, x1, y1 = _poly_.bounds\n",
    "                closest_y = None\n",
    "                for _y_ in new_y_lu:\n",
    "                    if   closest_y is None: closest_y = _y_\n",
    "                    elif abs(_y_ - y1) < abs(closest_y - y1): closest_y = _y_\n",
    "                new_y = new_y_lu[closest_y]\n",
    "                _poly_translated_ = affinity.translate(_poly_, 0, new_y - y1 + 2)\n",
    "                svg_for_this_highlighter.append(f'<path d=\"{self.rt_self.shapelyPolygonToSVGPathDescription(_poly_translated_)}\" fill=\"{_color_}\" opacity=\"{opacity}\" />')\n",
    "        svg_dict[highlighter] = f'<svg x=\"0\" y=\"0\" width=\"{max_x_rendered + self.x_ins}\" height=\"{max_y_rendered + self.y_ins}\">' + \\\n",
    "                                ''.join(_svg_) + ''.join(svg_for_this_highlighter) + '</svg>'\n",
    "\n",
    "    return svg_dict\n",
    "\n",
    "_tb2_ = rt.textBlock(passage, word_wrap=True, w=700)\n",
    "\n",
    "my_svg_dict   = compareHighlightsPixelReprsWExtra(_tb2_, my_markups)\n",
    "_example_svg_ =list(my_svg_dict.values())[0]\n",
    "w, h          = rt.__extractSVGWidthAndHeight__(_example_svg_)\n",
    "_spacer_      = rt.spacer(20, h, '#000000')\n",
    "_list_        = []\n",
    "for _svg_ in my_svg_dict.values(): \n",
    "    if len(_list_) > 0: _list_.append(_spacer_)\n",
    "    _list_.append(_svg_)\n",
    "rt.tile([_list_[0], _list_[1], _tb2_.highlights(all_lus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
