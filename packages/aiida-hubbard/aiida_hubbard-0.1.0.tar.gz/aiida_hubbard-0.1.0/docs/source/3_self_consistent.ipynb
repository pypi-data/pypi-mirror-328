{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(tutorials-hubbard-selfconsistent)=\n",
    "\n",
    "# Computing Hubbard parameters self-consistently\n",
    "\n",
    "In this tutorial you will learn how to compute iteratively the Hubbard parameters through the {py:class}`~aiida_hubbard.workflows.hubbard.SelfConsistentHubbardWorkChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from local_module import load_temp_profile\n",
    "from aiida_quantumespresso.data.hubbard_structure import HubbardStructureData\n",
    "\n",
    "# If you download this file, you can run it with your own profile.\n",
    "# Put these lines instead:\n",
    "# from aiida import load_profile\n",
    "# load_profile()\n",
    "data = load_temp_profile(\n",
    "    name=\"hubbard-selfconsistent-tutorial\",\n",
    "    add_computer=True,\n",
    "    add_pw_code=True,\n",
    "    add_hp_code=True,\n",
    "    add_sssp=True,\n",
    ")\n",
    "\n",
    "# We initialize only the U, so that `hp.x` will understand it\n",
    "# needs to compute only the onsite parameters.\n",
    "a, b, c, d = 1.40803, 0.81293, 4.68453, 1.62585\n",
    "cell = [[a, -b, c], [0.0, d, c], [-a, -b, c]]\n",
    "sites = [\n",
    "    ['Co', 'Co', (0, 0, 0)],\n",
    "    ['O',   'O', (0, 0, 3.6608)], \n",
    "    ['O',   'O', (0, 0, 10.392)], \n",
    "    ['Li', 'Li', (0, 0, 7.0268)],\n",
    "]\n",
    "\n",
    "hubbard_structure = HubbardStructureData(cell=cell, sites=sites)\n",
    "hubbard_structure.initialize_onsites_hubbard(\"Co\", \"3d\")\n",
    "hubbard_structure.store()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cycle\n",
    "\n",
    "To have a full ab-initio calculation of Hubbard parameters, an iterative procedure should be employed. This forsees the following steps, to do in a cyclic way till the parameters don't differ from the previous ones by a certain threshold, i.e. ___self-consistently___.\n",
    "\n",
    "The steps to do in order are:\n",
    "1. Perform a volume relaxation of the structure, starting from a zero value of Hubbard parameters (i.e. if it was a 'non-Hubbard' calculation).\n",
    "2. Perform the ground-state calculation (SCF) of the relaxed structure.\n",
    "3. Perform the linear response calculation to predict the new Hubbard values.\n",
    "4. If _all_ U (and V) are within the desired threshold, stop, otherwise restart with the new values from (1).\n",
    "\n",
    "::: {admonition} Note for SCF (step 2)\n",
    ":class: note\n",
    "\n",
    "Tipically, as these are electronic responses, the gound-state SCF can be performed _with looser energy cutoffs and k poit density_, and still retain the same accuracy on the prediction of Hubbard parameters. \n",
    "\n",
    "```{important}\n",
    "Before any production run, you should make sure to have converged such parameters.\n",
    "```\n",
    ":::\n",
    "\n",
    "::: {admonition} Note for thresholds\n",
    ":class: note\n",
    "\n",
    "Threshold for U and V may depend on the final goal, or property, of your research. From our experience, good values are of the order of 0.1 eV for the onsite parameters (U) and 0.01 eV for the intersites (V).\n",
    ":::\n",
    "\n",
    "### Automating the cycle\n",
    "\n",
    "As we already learnt from the previous tutorials ([1](./1_computing_hubbard.ipynb),[2](./2_parallel_hubbard.ipynb)), we can simply fill the builder of the work chain using the `get_builder_from_protocol` to get to know what the workflow is doing, and how this can help  and speed up our research.\n",
    "\n",
    ":::{warning}\n",
    "In this tutorial we will compute only the U on Co, and not the V for Co-O. This is to speed up the simulation, which on only a handful of cores would take tens of minutes, if not more.\n",
    "\n",
    "This workflow may take 5 minutes (or more) to complete depending on your local resources.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from aiida.engine import run_get_node\n",
    "from aiida_hubbard.workflows.hubbard import SelfConsistentHubbardWorkChain\n",
    "\n",
    "builder = SelfConsistentHubbardWorkChain.get_builder_from_protocol(\n",
    "    pw_code=data.pw_code, \n",
    "    hp_code=data.hp_code, \n",
    "    hubbard_structure=hubbard_structure,\n",
    "    protocol=\"fast\",\n",
    "    overrides={\n",
    "        \"clean_workdir\": False,\n",
    "        \"tolerance_onsite\": 0.5,\n",
    "        \"tolerance_intersite\": 0.1,\n",
    "        \"relax\":{\n",
    "            \"base\":{\n",
    "                \"kpoints_distance\":100.0,\n",
    "                \"pw\":{\n",
    "                    \"parameters\":{\n",
    "                        \"SYSTEM\":{\n",
    "                            \"ecutwfc\": 60.0, # to speed up the tutorial\n",
    "                            \"ecutrho\": 60.0 * 8,\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        }, # to speed up the tutorial\n",
    "        \"scf\":{\n",
    "            \"kpoints_distance\":100.0, \n",
    "            \"pw\":{\n",
    "                \"parameters\":{\n",
    "                    \"SYSTEM\":{\n",
    "                        \"ecutwfc\": 30.0, # to speed up the tutorial\n",
    "                        \"ecutrho\": 30.0 * 8,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        }, \n",
    "        \"hubbard\":{\"qpoints_distance\":100.0, \"parallelize_atoms\":False, \"parallelize_qpoints\":False}}, # to speed up the tutorial\n",
    ")\n",
    "\n",
    "results, node = run_get_node(builder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the status of the work chain to see the full self-consistency on screen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%verdi process status {node.pk}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, here you have the final __relaxed__ structure with __fully self-consistent ab-initio Hubbard parameters__! :tada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida_quantumespresso.utils.hubbard import HubbardUtils\n",
    "print(HubbardUtils(results['hubbard_structure']).get_hubbard_card())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final considerations\n",
    "\n",
    "We managed to compute the Hubbard parameters self-consistently with a series of relaxations, scfs, and hp calculations, ___all fully automated___! :tada:\n",
    "\n",
    "\n",
    ":::{admonition} Learn more and in details\n",
    ":class: hint\n",
    "\n",
    "To learn the full sets of inputs, to use proficiently the `get_builder_from_protocol` and more, have a look at the following sections:\n",
    "- [Specific how tos](howto/workflows/hubbard.md)\n",
    "- [General information of the implemented workchain](topics/workflows/hubbard.md)\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
